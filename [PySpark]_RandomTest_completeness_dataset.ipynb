{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1OlxKg1jl+EHAKP7FJvLu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Test of completeness for large dataset (million or billions)"
      ],
      "metadata": {
        "id": "6D8GvC0LPvi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement a random test case on millions or billions of data rows using PySpark\n"
      ],
      "metadata": {
        "id": "U3C60eCZ-CJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "!pip install unidecode"
      ],
      "metadata": {
        "id": "8i3DPBJVDpTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pyspark as spark\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "     \n",
        "\n",
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "# Create a Spark Session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# Check Spark Session Information\n",
        "print(spark)\n",
        "     \n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh7Ahju0Dw4v",
        "outputId": "14384de5-3b6f-4dd0-eb02-20682215881d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pyspark.sql.session.SparkSession object at 0x7f6a18af2d30>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynR-JGP897Sa",
        "outputId": "b2eebaa1-3d89-4d72-a4e4-90386f000451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  908k  100  908k    0     0  1678k      0 --:--:-- --:--:-- --:--:-- 1675k\n"
          ]
        }
      ],
      "source": [
        "!curl https://raw.githubusercontent.com/vamsikrishnaprasad/predictive-Analytics-for-Retail-Banking/master/bank.csv --output bank.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bank_df = spark.read.option(\"header\",True).csv(\"bank.csv\")"
      ],
      "metadata": {
        "id": "-FHuquNfC9H5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bank_df.show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS-gkdGjEM9d",
        "outputId": "8280b7c7-01a1-46a1-f213-fa6b39f07229"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|age|job       |marital|education|fault|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
            "+---+----------+-------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|59 |admin.    |married|secondary|no   |2343   |yes    |no  |unknown|5  |may  |1042    |1       |-1   |0       |unknown |yes    |\n",
            "|56 |admin.    |married|secondary|no   |45     |no     |no  |unknown|5  |may  |1467    |1       |-1   |0       |unknown |yes    |\n",
            "|41 |technician|married|secondary|no   |1270   |yes    |no  |unknown|5  |may  |1389    |1       |-1   |0       |unknown |yes    |\n",
            "|55 |services  |married|secondary|no   |2476   |yes    |no  |unknown|5  |may  |579     |1       |-1   |0       |unknown |yes    |\n",
            "|54 |admin.    |married|tertiary |no   |184    |no     |no  |unknown|5  |may  |673     |2       |-1   |0       |unknown |yes    |\n",
            "+---+----------+-------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FRACTION = 0.1 # sampling 10% of rows\n",
        "bank_df.sample(fraction = FRACTION).show(5, False)\n",
        "\n",
        "bank_df.sample(fraction = FRACTION, seed=100).show(5, False)\n",
        "bank_df.sample(fraction = FRACTION, seed=100).show(5, False)\n",
        "bank_df.sample(fraction = FRACTION, seed=200).show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rR9RjlgEaFB",
        "outputId": "a957c55e-23e8-45e6-d718-49ac5bc82e96"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|age|job        |marital |education|fault|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|56 |management |married |tertiary |no   |830    |yes    |yes |unknown|6  |may  |1201    |1       |-1   |0       |unknown |yes    |\n",
            "|41 |admin.     |married |secondary|no   |55     |yes    |no  |unknown|8  |may  |1120    |2       |-1   |0       |unknown |yes    |\n",
            "|28 |admin.     |divorced|secondary|no   |785    |yes    |no  |unknown|8  |may  |442     |2       |-1   |0       |unknown |yes    |\n",
            "|26 |blue-collar|single  |secondary|no   |82     |yes    |no  |unknown|9  |may  |654     |1       |-1   |0       |unknown |yes    |\n",
            "|42 |technician |single  |secondary|no   |1364   |yes    |no  |unknown|15 |may  |1867    |6       |-1   |0       |unknown |yes    |\n",
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|age|job        |marital |education|fault|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|42 |management |single  |tertiary |no   |0      |yes    |yes |unknown|5  |may  |562     |2       |-1   |0       |unknown |yes    |\n",
            "|56 |management |married |tertiary |no   |830    |yes    |yes |unknown|6  |may  |1201    |1       |-1   |0       |unknown |yes    |\n",
            "|43 |blue-collar|married |primary  |no   |-192   |yes    |no  |unknown|8  |may  |1120    |2       |-1   |0       |unknown |yes    |\n",
            "|37 |unemployed |single  |secondary|no   |381    |yes    |no  |unknown|8  |may  |985     |2       |-1   |0       |unknown |yes    |\n",
            "|48 |blue-collar|divorced|primary  |no   |24     |yes    |no  |unknown|14 |may  |832     |1       |-1   |0       |unknown |yes    |\n",
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|age|job        |marital |education|fault|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|42 |management |single  |tertiary |no   |0      |yes    |yes |unknown|5  |may  |562     |2       |-1   |0       |unknown |yes    |\n",
            "|56 |management |married |tertiary |no   |830    |yes    |yes |unknown|6  |may  |1201    |1       |-1   |0       |unknown |yes    |\n",
            "|43 |blue-collar|married |primary  |no   |-192   |yes    |no  |unknown|8  |may  |1120    |2       |-1   |0       |unknown |yes    |\n",
            "|37 |unemployed |single  |secondary|no   |381    |yes    |no  |unknown|8  |may  |985     |2       |-1   |0       |unknown |yes    |\n",
            "|48 |blue-collar|divorced|primary  |no   |24     |yes    |no  |unknown|14 |may  |832     |1       |-1   |0       |unknown |yes    |\n",
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|age|job        |marital |education|fault|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|deposit|\n",
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "|59 |admin.     |married |secondary|no   |2343   |yes    |no  |unknown|5  |may  |1042    |1       |-1   |0       |unknown |yes    |\n",
            "|35 |blue-collar|single  |secondary|no   |40     |yes    |no  |unknown|9  |may  |617     |4       |-1   |0       |unknown |yes    |\n",
            "|40 |blue-collar|married |secondary|no   |10     |yes    |no  |unknown|9  |may  |1692    |2       |-1   |0       |unknown |yes    |\n",
            "|48 |management |married |tertiary |no   |1949   |yes    |no  |unknown|13 |may  |683     |2       |-1   |0       |unknown |yes    |\n",
            "|53 |technician |divorced|primary  |no   |1443   |yes    |no  |unknown|14 |may  |476     |1       |-1   |0       |unknown |yes    |\n",
            "+---+-----------+--------+---------+-----+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This particular use case was rather interesting and allowed me to put into practice the sample() function. I had a number of CSV file on the one hand, notably from a different source system, and had to check that the data existed in the actual dataset, containing billions of rows. As it wasn’t feasible to validate every single row, I generated some sample data from the CSV file, placed that data in a pandas dataframe to later convert it into a list, then using the filter() command, extracted the row from the actual dataset, based on the primary keys. If results were returned from the filter() command, then I knew that the row existed in the actual dataset. If not — ERROR!!!"
      ],
      "metadata": {
        "id": "ETMCVCExDPuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bank_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5fLNHT9Hywg",
        "outputId": "ac109ee4-b481-4acd-c6dd-98f5d1616793"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11162"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "schema = StructType([\n",
        "StructField(\"id\",IntegerType(),True),\n",
        "StructField(\"name\",StringType(),True),\n",
        "StructField(\"age\",IntegerType(),True)])\n",
        "\n",
        "# This data is what we will sample\n",
        "expected_data=[(1, \"Brooke\", 20),\n",
        "(2, \"Jon\", 45),\n",
        "(3, \"Susan\", 53),\n",
        "(9, \"Axl\", 21)] # Axl is the data row that is NOT found in actual dataset\n",
        "\n",
        "actual_data=[(1, \"Brooke\", 20),\n",
        "(2, \"Jon\", 45),\n",
        "(3, \"Susan\", 53),\n",
        "(4, \"Mary\", 46),\n",
        "(5, \"Adam\", 6),\n",
        "(6, \"Brian\", 9),\n",
        "(7, \"Melanie\", 5),\n",
        "(8, \"Sarah\", 10)]\n",
        "\n",
        "expected_df = spark.createDataFrame(data=expected_data, schema=schema)\n",
        "actual_df = spark.createDataFrame(data=actual_data,schema=schema)\n",
        "\n",
        "sample_df = expected_df.sample(fraction=0.6) # get a sample of the expected dataset\n",
        "\n",
        "pandas_df = sample_df.toPandas()\n",
        "sample_df.show() # sample values that will be searched\n",
        "\n",
        "vals = pandas_df.values\n",
        "listValues = vals.tolist() # turn pandas into a list, as it is a small number of results\n",
        "\n",
        "print(listValues)\n",
        "\n",
        "# Loop over the list of sampled data, checking whether it exists in the actual dataset\n",
        "for line in listValues:\n",
        "   count = 0\n",
        "   primary_key = line[0]\n",
        "   count = actual_df.filter(condition=actual_df.id==primary_key).count()\n",
        "   if count == 0: print(\"Row not found \" + str(primary_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meZKQ5t0MN2d",
        "outputId": "20ff5e58-a3d2-48b7-be22-107540d2213b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+---+\n",
            "| id| name|age|\n",
            "+---+-----+---+\n",
            "|  2|  Jon| 45|\n",
            "|  3|Susan| 53|\n",
            "|  9|  Axl| 21|\n",
            "+---+-----+---+\n",
            "\n",
            "[[2, 'Jon', 45], [3, 'Susan', 53], [9, 'Axl', 21]]\n",
            "Row not found 9\n"
          ]
        }
      ]
    }
  ]
}